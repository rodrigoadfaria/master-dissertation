%% ------------------------------------------------------------------------- %%
\chapter{Introduction}
\label{cap:introducao}
Skin detection can be defined as the process of identifying skin-colored pixels in an image. It plays an important role in a wide range of image processing and computer vision applications such as face detection, pornographic image filtering, gesture analysis, face tracking, video surveillance systems, medical image analysis, and other human-related image processing applications.

The problem is complex because of the numerous similar materials with human skin tone and texture, and also because of illumination conditions, ethnicity, sensor capturing singularities, geometric variations, etc. Because it is a primary task in image processing, additional requirements as real time processing, robustness and accuracy are also desirable.

Skin color is a strong characteristic and it is used in most algorithms for skin detection. It is normally used along with other features such as shape, texture, and geometry, or even as a preliminary step to classify regions of interest in an image.

The human skin color pixels have a restricted range of hues and are not deeply saturated, since the appearance of skin is formed by a combination of blood (red) and melanin (brown, yellow), which leads the human skin color to be clustered within a small area in the color space~\citep{fleck:96}.

The choice of a color space is also a key point of a feature-based method when using skin color as a detection cue. Due to its sensitivity to illumination, the input image is, in general, first transformed into a color space whose luminance and chrominance components can be separate to mitigate the problem~\citep{vezhnevets:03}.

Color has the ability of functioning as a descriptor that often simplifies the identification and extraction of an object in a scene. Moreover, the ability of humans to discern thousands of tonalities and intensities compared to only a few dozen levels of gray, put the color as a strong candidate feature in computer vision and image processing applications~\citep{gonzalez:02}.

Basically, there are three approaches for skin detection: rule-based, machine learning based and hybrid. They differ in terms of classification accuracy and computational efficiency. Machine learning and hybrid methods require a training set, from which the decision rules are learned. Such approaches outperform the rule-based methods but require a large and representative training dataset as well as it takes a long classification time, which can be a deal breaker for real time applications~\citep{kakumanu:07}.

In this work we propose an improvement of a novel method on rule-based skin detection that works in the YCbCr color space~\citep{brancati:17}. Our motivation is based on the hypothesis that the original rule can be complemented with another rule that is a reversal interpretation of the one proposed originally. Besides that, we also take in consideration that a skin pixel does not appear isolated, so we propose another variation based on neighborhood operations. The set of rules evaluate the combinations of chrominance Cb, Cr values to identify the skin pixels depending on the shape and size of dynamically generated skin color clusters \citep{brancati:17}. The method is very efficient in terms of computational effort as well as robust in very complex image scenes.

%% ------------------------------------------------------------------------- %%
\section{Motivação}
\label{sec:consideracoes_preliminares}

Há diversos objetos ou observações na natureza que não podem ser classificados com conjuntos clássicos pelo fato de que a relação de pertinência não é bem definida \citep{pedrycz:98}. Especificamente no campo da visão computacional, vários problemas reais de classificação só podem ser resolvidos quando da análise do contexto onde o problema está inserido.

Sendo assim, a motivação deste trabalho está em analisar problemas reais de visão computacional cujos conjuntos de dados possuem incerteza e imprecisão, modelando-os por meio de conjuntos \emph{fuzzy}, explorando a capacidade desses conjuntos de expressarem transições graduais de pertinência e não pertinência.


%% ------------------------------------------------------------------------- %%
\section{Trabalhos relacionados}
\label{sec:trabalhos_relacionados}

\textcolor{red}{Check if we will keep fuzzy part + ML approaches to move this part to next chapter}.

Em alguns problemas de classificação, o uso de dados intervalares pode ser uma ferramenta poderosa na obtenção de bons resultados. Intervalos representados por conjuntos \emph{fuzzy} também têm grande valia nesta tarefa. Com base nessa característica, \citet{umano:94} propuseram um algoritmo para gerar uma árvore de decisão \emph{fuzzy}, a partir de dados numéricos, usando conjuntos \emph{fuzzy} previamente definidos. Essa implementação é uma adaptação do algoritmo Divisor Iterativo 3 (ID3) clássico proposto por \citet{quinlan:86}, brevemente discutido na seção \ref{sec:classifiers_dt}. A diferença fundamental para o ID3 está no método de seleção do atributo que particiona o conjunto de dados. Assim como no ID3, aqui também é utilizado o ganho de informação como critério, porém, ao invés de aplicar o valor dos atributos no cálculo, o algoritmo computa pelo grau de pertinência dos conjuntos \emph{fuzzy}. Outra propriedade particular da árvore \emph{fuzzy} está no processo de inferência, pois permite que mais de um ramo seja ativado quando um atributo é testado na avaliação do grau de pertinência.

O \emph{fuzzy} ID3 foi utilizado por \citet{bhatt:09} para segmentação de regiões de pele. O conjunto de dados aplicado no experimento contém os três canais de cores do modelo Vermelho, Verde e Azul (RGB) e também foi utilizado nos experimentos deste trabalho, conforme pode ser visto no capítulo \ref{cap:experimentos}. Antes da indução da árvore, os dados de treinamento foram aglomerados em cinco \emph{clusters} por meio do algoritmo \emph{fuzzy c-means} \citep{bezdek:84}. Os \emph{clusters} foram aproximados com função de pertinência gaussiana. A taxa de erro obtida foi de 94,1\%.

Outra variante de árvore de decisão para conjuntos \emph{fuzzy} é a proposta de \citet{cintra:13}, porém, baseada na versão clássica C4.5, uma versão estendida do ID3 também criada por \citet{quinlan:93}. Chamado de \emph{FuzzyDT}, o algoritmo igualmente usa a entropia e o ganho de informação do C4.5 como medidas para decidir sobre a importância dos atributos. A estratégia de indução da árvore também é a mesma, ou seja, os dados são particionados recursivamente criando ramos até que uma classe é atribuída a cada folha. Porém, antes da indução da árvore, os atributos contínuos são definidos em termos de conjuntos \emph{fuzzy}. Em outras palavras, a árvore é induzida com os valores dos atributos "discretizados", isto é, transformados em intervalos finitos, ou "discretos". O domínio dos conjuntos \emph{fuzzy} devem ser estabelecidos previamente pelo usuário. Experimentos foram realizados com 16 conjuntos de dados distintos obtidos de \citet{lichman:13}, comparando o desempenho do algoritmo com o C4.5 em termos da taxa de erro, número médio de regras e condições geradas por ambas técnicas. Em resumo, o \emph{FuzzyDT} produziu resultados satisfatórios na maioria dos conjuntos de dados avaliados. O algoritmo foi utilizado para experimentos preliminares que podem ser vistos no capítulo \ref{cap:experimentos}.

Vale ressaltar que o \emph{FuzzyDT} contém quatro métodos distintos de estimar o número de conjuntos \emph{fuzzy} para cada atributo do conjunto de dados \citep{cintra:11}. Um deles define um número de conjuntos \emph{fuzzy} uniforme para todos os atributos. Os demais são flexíveis, ou seja, permitem que o número de conjuntos \emph{fuzzy} para cada atributo seja distinto. Um desses métodos é o ganho de informação, calculado e armazenado para cada atributo após o processo de "fuzzificação" dos valores contínuos. O processo é repetido 8 vezes, utilizando de 2 a 9 conjuntos \emph{fuzzy} para cada atributo. A base de dados final é, então, formada com o número de conjuntos \emph{fuzzy} que produziram o maior ganho de informação para cada atributo. O segundo método é oriundo do algoritmo RELIEF que mede a utilidade dos atributos com base em sua capacidade de distinguir entre amostras semelhantes pertencentes a classes distintas. Ele produz um ranking de mérito médio dos atributos e funciona tanto em dados discretos como contínuos \citep{kononenko:94}. O terceiro método é a implementação da técnica proposta por \citet{wang:03} e conhecida como Wang-Mendel (WM), onde cada atributo é definido usando de 2 a 9 conjuntos \emph{fuzzy} e, em seguida, usado individualmente para gerar um classificador WM. As taxas de erro obtidas do classificador são usadas como critério para selecionar o número de conjuntos \emph{fuzzy}. Os métodos foram avaliados em 11 conjuntos de dados, sendo que os métodos flexíveis mostraram melhores taxas de erro.


%% ------------------------------------------------------------------------- %%
\section{Objetivos}
\label{sec:objetivo}

O principal objetivo deste projeto de mestrado está na avaliação de conjuntos \emph{fuzzy} na aplicação em problemas de classificação em visão computacional, estabelecendo mecanismos comparativos, por meio de indicadores quantitativos e qualitativos, para mensurar seu desempenho em relação aos conjuntos clássicos.

Além disso, a escolha do espaço de cores para a modelagem dos dados como conjuntos \emph{fuzzy} também será analisada com o intuito de compreender sua influência nos resultados obtidos pelo classificador.


%% ------------------------------------------------------------------------- %%
\section{Organização do texto}
\label{sec:organizacao_trabalho}

Quanto à organização deste trabalho, no capítulo~\ref{cap:conceitos} são explicitados conceitos fundamentais sobre diferentes modelos de cores, teoria \emph{fuzzy} e classificadores utilizados no desenvolvimento deste estudo. No capítulo~\ref{cap:experimentos}, são expostos os resultados de experimentos preliminares com conjuntos de dados de pele de seres humanos, bem como a avaliação da influência do modelo de cores escolhido para tratar este tipo de problema de classificação. Por fim, o capítulo~\ref{cap:conclusoes} apresenta o plano de trabalho com as atividades a serem realizadas no âmbito desta pesquisa.
