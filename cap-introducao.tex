%% ------------------------------------------------------------------------- %%
\chapter{Introdução}
\label{cap:introducao}


%% ------------------------------------------------------------------------- %%
\section{Motivação}
\label{sec:consideracoes_preliminares}

Há inúmeros indivíduos ou observações na natureza que não podem ser classificados com conjuntos clássicos pelo fato de que a relação de pertinência não é bem definida \citep{pedrycz:98}. Especificamente no campo da visão computacional, vários problemas reais de classificação só podem ser resolvidos quando da análise do contexto onde o problema está inserido.

Sendo assim, a motivação deste trabalho está em analisar problemas reais de visão computacional cujos conjuntos de dados possuem incerteza e imprecisão, modelando-os por meio de conjuntos \emph{fuzzy}, explorando a capacidade desses conjuntos de expressarem transições graduais de pertinência e não pertinência.


%% ------------------------------------------------------------------------- %%
\section{Trabalhos relacionados}
\label{sec:trabalhos_relacionados}

Em alguns problemas de classificação, o uso de dados intervalares pode ser uma ferramenta poderosa na obtenção de bons resultados. Intervalos representados por conjuntos \emph{fuzzy} também têm grande valia nesta tarefa. Com base nessa característica, \citet{umano:94} propuseram um novo algoritmo para gerar uma árvore de decisão \emph{fuzzy}, a partir de dados numéricos, usando conjuntos \emph{fuzzy} previamente definidos. Essa implementação é uma adaptação do algoritmo Divisor Iterativo 3 (ID3) clássico proposto por \citet{quinlan:86}, brevemente discutido na seção \ref{sec:clasificadores_arvores_decisao}. A diferença fundamental para o ID3 está no método de seleção do atributo que particiona o conjunto de dados. Assim como no ID3, aqui também é utilizado o ganho de informação como critério, porém, ao invés de aplicar o valor dos atributos no cálculo, o algoritmo computa pelo grau de pertinência dos conjuntos \emph{fuzzy}. Outra propriedade particular da árvore \emph{fuzzy} está no processo de inferência, pois permite que mais de um ramo seja ativado quando um atributo é testado na avaliação do grau de pertinência.

O \emph{fuzzy} ID3 foi utilizado por \citet{bhatt:09} para segmentação de regiões de pele. O conjunto de dados aplicado no experimento contém os três canais de cores do modelo Vermelho, Verde e Azul (RGB) e também foi utilizado nos experimentos deste trabalho, conforme pode ser visto no Capítulo \ref{cap:experimentos}. Antes da indução da árvore, os dados de treinamento foram aglomerados em cinco \emph{clusters} por meio do algoritmo \emph{fuzzy c-means}. Os \emph{clusters} foram aproximados com função de pertinência gaussiana. A taxa de erro obtida foi de 94,1\%.

Outra variante de árvore de decisão para conjuntos \emph{fuzzy} é a proposta de \citet{cintra:13}, porém, baseada na versão clássica C4.5, uma versão estendida do ID3 também criada por \citet{quinlan:93}. Chamado de \emph{FuzzyDT}, o algoritmo igualmente usa a entropia e o ganho de informação do C4.5 como medidas para decidir sobre a importância dos atributos. A estratégia de indução da árvore também é a mesma, ou seja, os dados são particionados recursivamente criando ramos até que uma classe é atribuída a cada folha. Porém, antes da indução da árvore, os atributos contínuos são definidos em termos de conjuntos \emph{fuzzy}. Em outras palavras, a árvore é induzida com os valores dos atributos "discretizados". O domínio dos conjuntos \emph{fuzzy} devem ser estabelecidos previamente pelo usuário. Experimentos foram realizados com 16 conjuntos de dados distintos obtidos de \citet{lichman:13}, comparando o desempenho do algoritmo com o C4.5 em termos da taxa de erro, número médio de regras e condições geradas por ambas técnicas. Em resumo, o \emph{FuzzyDT} produziu resultados satisfatórios na maioria dos conjuntos de dados avaliados. O algoritmo foi utilizado para experimentos preliminares que podem ser vistos no Capítulo \ref{cap:experimentos}.

Vale ressaltar que o \emph{FuzzyDT} contém quatro métodos distintos de estimar o número de conjuntos \emph{fuzzy} para cada atributo do conjunto de dados \citep{cintra:11}. Um deles define um número de conjuntos \emph{fuzzy} uniforme para todos os atributos. Os demais são flexíveis, ou seja, permitem que o número de conjuntos \emph{fuzzy} para cada atributo seja distinto. Um desses métodos é o ganho de informação, calculado e armazenado para cada atributo após o processo de "fuzzificação" dos valores contínuos. O processo é repetido 8 vezes, utilizando de 2 a 9 conjuntos \emph{fuzzy} para cada atributo. A base de dados final é, então, formada com o número de conjuntos \emph{fuzzy} que produziram o maior ganho de informação para cada atributo. O segundo método é oriundo do algoritmo RELIEF que mede a utilidade dos atributos com base em sua capacidade de distinguir entre amostras semelhantes pertencentes a classes distintas. Ele produz um ranking de mérito médio dos atributos e funciona tanto em dados discretos como contínuos \citep{kononenko:94}. O terceiro método é a implementação da técnica proposta por \citet{wang:03} e conhecida como Wang-Mendel (WM), onde cada atributo é definido usando de 2 a 9 conjuntos \emph{fuzzy} e, em seguida, usado individualmente para gerar um classificador WM. As taxas de erro obtidas do classificador são usadas como critério para selecionar o número de conjuntos \emph{fuzzy}. Os métodos foram avaliados em 11 conjuntos de dados, sendo que os métodos flexíveis mostraram melhores taxas de erro.

\citet{guevara:14} propõem uma formulação geral de \emph{kernel} sobre conjuntos \emph{fuzzy} e, além disso, define exemplos de construção de \emph{kernels fuzzy} positivos definidos, tais como, polinomial e gaussiano, para resolver problemas de aprendizagem computacional, em particular de aprendizagem supervisionada, como os estudos presentes neste trabalho. Experimentos foram realizados com diferentes conjuntos de dados de baixa qualidade, ou seja, dados cujo valor dos atributos possuem um certo grau de incerteza, por possuírem amostras com valores ausentes e atributos com valores intervalares. O classificador utilizado foi Máquina de Vetores Suporte (SVM), sendo que a Função de Base Radial (RBF) é o \emph{kernel} usado para efeito comparativo. Resultados mostraram que os \emph{kernels} propostos, na maioria dos casos, superam o desempenho do RBF.

Como os experimentos preliminares do presente estudo baseiam-se na aplicação de classificadores em detecção de cor de pele baseado na informação de cor, uma série de trabalhos nesse campo também foram explorados. Alguns deles ocuparam-se de avaliar, comparativamente, diversos tipos de técnicas e classificadores, principalmente sob o ponto de vista de desempenho, modelos de cores, modelagem da cor da pele e diferentes conjuntos de dados \citep{vezhnevets:03,kakumanu:07,mahmoodi:16}.

\citet{jones:02} aplicaram a regra de decisão Bayesiana com um modelo de histograma $3$-dimensional construído a partir de, aproximadamente, 2 bilhões de pixels coletados de 18.696 imagens da internet para realizar a detecção de pele. \citet{jones:02} calcularam dois histogramas diferentes para pele e não pele no espaço de cores RGB. Tendo os histogramas com os dados de treinamento, o classificador foi derivado com a abordagem de proporção da probabilidade de que um pixel é pele para a probabilidade de que é não pele. Tal abordagem usa um limiar que pode ser ajustado para equilibrar a detecção correta e os falsos positivos. Os histogramas de tamanho 32 mostraram o melhor desempenho com uma taxa de erro de 88\%.

Outro método para construir um classificador de pele é definir, explicitamente, através de um número de regras, as fronteiras que delimitam o agrupamento dos pixels de pele em algum espaço de cores \citep{vezhnevets:03}. Esta foi a abordagem adotada por \citet{kovac:03} no espaço de cores YCbCr, tendo obtido uma taxa de verdadeiro positivo de 90,66\%. \citet{kovac:03} também realizaram experimentos apenas com os canais de cromaticidade Cb e Cr. Os resultados reduzem significativamente o desempenho do classificador. A vantagem óbvia deste método é a simplicidade das regras de detecção de pele que leva à construção de um classificador muito rápido. Por outro lado, a dificuldade em alcançar altas taxas de reconhecimento com este método é a necessidade de encontrar um bom espaço de cores e regras de decisão adequadas empiricamente \citep{vezhnevets:03}.

Diferentemente da proposta de \citet{kovac:03}, \citet{yogarajah:11} desenvolveram uma técnica onde os limiares definidos nas regras são adaptados dinamicamente. O método consiste em detectar a região dos olhos e extrair uma região elíptica da face. Posteriormente, um filtro de Sobel é aplicado para detectar as bordas da região resultante que, por sua vez, é submetida a uma dilatação. A imagem resultante é subtraída da imagem elíptica da face original. Como resultado tem-se uma região de pele mais uniforme onde os limiares são calculados. A técnica foi utilizada como uma etapa de pré processamento por \citet{tan:12} numa estratégia que combina um histograma de densidades $2$-dimensional e um modelo Gaussiano para detecção de cor de pele. Os resultados mostraram uma acurácia de 90,39\%.

\citet{naji:12} construíram um classificador explícito no espaço de cores HSV para 4 diferentes etnias de pele em paralelo. Após a segmentação primitiva, é aplicado um algoritmo de crescimento de região baseado em regras, no qual a saída da primeira camada é usada como uma semente e, em seguida, a máscara final em outras camadas é construída iterativamente por meio de pixels de pele vizinhos. Uma das medidas de desempenho reportadas foi o número de pixels verdadeiros positivos no valor de 96,5\%.

\citet{kawulok:13} combinaram informações globais e locais da imagem para construir um mapa de probabilidade que é usado para gerar a semente inicial para análise espacial dos pixels de pele. As sementes extraídas utilizando um modelo local são altamente adaptadas à imagem, o que melhora muito o resultado da análise espacial.

Embora a cor não seja utilizada diretamente em algumas abordagens de detecção de pele, é uma das ferramentas mais decisivas que afetam o desempenho dos algoritmos \citep{mahmoodi:16}. Apesar do desempenho da maioria dos detectores de pele estar diretamente relacionado com a escolha do espaço de cores, \citet{albiol:01} provaram, matematicamente, que o desempenho ótimo dos classificadores de pele é independente do espaço de cores escolhido.

O RGB é o espaço de cores mais comumente utilizado para armazenar e representar imagens digitais, uma vez que as câmeras são habilitadas a fornecer as imagens nesse modelo. Para reduzir a influência da iluminação, os canais RGB podem ser normalizados, de modo que a soma dos componentes normalizados é unitária, ou seja, tem valor 1. Por conseguinte, o terceiro componente pode ser removido, já que não fornece informação significativa, o que reduz a dimensionalidade do problema \citep{kakumanu:07}. Essa característica levou \citet{bergasa:00} a construirem um modelo Gaussiano adaptativo e não supervisionado para segmentar pele no espaço de cores RGB normalizado, usando apenas os canais $r$ e $g$ \footnote{$r$, $g$ e $b$ são normalmente utilizados para representar os canais do modelo RGB normalizado \citep{gonzalez:02}.}.

\citet{jayaram:04} desenvolveram um estudo comparativo usando abordagens Gaussiana e histograma em um conjunto de dados de 805 imagens coloridas em 9 espaços de cores distintos. Os resultados revelaram que a ausência do componente de luminância, ou seja, utilizando apenas dois canais do espaço de cor, impacta significativamente no desempenho, bem como a seleção do espaço de cores. Os melhores resultados foram obtidos nos espaços de cores SCT, HSI e CIELab com abordagem de histograma.

\citet{chaves:10} compararam o desempenho de 10 espaços de cor com base no algoritmo de agrupamento \emph{k-means} em 15 imagens do banco de imagens de faces de Aleix e Robert (AR) \citep{ar-face-database:98}. De acordo com os resultados obtidos, os espaços de cores mais apropriados para detecção de cor de pele são YCgCr, YDbDr e HSV, sendo este último o que produziu o melhor desempenho.

\citet{kaur:12} implementaram um algoritmo similar ao proposto por \citet{kovac:03} onde as fronteiras que delimitam o agrupamento dos pixels de pele são definidos por regras explícitas. Após a segmentação da imagem com as regras, o algoritmo também realiza operações morfológicas e de filtragem para melhorar a acurácia do método. \citet{kaur:12} aplicaram o algoritmo nos espaços de cor YCbCr e CIELab, ignorando o componente de luminância em ambos, que são Y e L, respectivamente. Os resultados foram mais satisfatórios quando o algoritmo foi aplicado sobre CIELab. Uma técnica similar foi implementada em \citet{shaik:15} e \citet{kumar:15} nos espaços de cores HSV e YCbCr, sendo este último o que proporcionou os melhores resultados em ambos.


%% ------------------------------------------------------------------------- %%
\section{Objetivos}
\label{sec:objetivo}

O principal objetivo deste projeto de mestrado está na avaliação de conjuntos \emph{fuzzy} na aplicação em problemas de classificação em visão computacional, estabelecendo mecanismos comparativos, por meio de indicadores quantitativos e qualitativos, para mensurar seu desempenho em relação aos conjuntos clássicos.

Além disso, a escolha do espaço de cores para a modelagem dos dados como conjuntos \emph{fuzzy} também será analisada com o intuito de compreender sua influência nos resultados obtidos pelo classificador.


%% ------------------------------------------------------------------------- %%
\section{Organização do texto}
\label{sec:organizacao_trabalho}

Quanto à organização deste trabalho, no Capítulo~\ref{cap:conceitos} são explicitados conceitos fundamentais sobre diferentes modelos de cores, teoria \emph{fuzzy} e classificadores utilizados no desenvolvimento deste estudo. O Capítulo~\ref{cap:experimentos}, são expostos os resultados de experimentos preliminares com conjuntos de dados de pele de seres humanos, bem como a avaliação da influência do modelo de cores escolhido para tratar este tipo de problema de classificação. Por fim, o Capítulo~\ref{cap:conclusoes} apresenta o plano de trabalho com as atividades a serem realizadas no âmbito desta pesquisa.
